# Base datasets

For a few datasets that FsDet natively supports,
the datasets are assumed to exist in a directory called
"datasets/", under the directory where you launch the program.
They need to have the following directory structure:

## Expected dataset structure for Pascal VOC:
```
VOC20{07,12}/
  Annotations/
  ImageSets/
  JPEGImages/
```
在官网分别下载VOC2007和VOC2012的图片和标注

## Expected dataset structure for COCO:
```
coco/
  annotations/
    instances_{train,val}2014.json
  {train,val}2014/
    # image files that are mentioned in the corresponding json
```
在`coco/`文件夹下，运行以下命令（因为文件较大，下载需要很长时间，所以建议通过`nohup`在后台运行下载命令）
```python
#### 下载COCO2014的train set和val set
wget http://images.cocodataset.org/zips/train2014.zip
# nohup wget http://images.cocodataset.org/zips/train2014.zip > wget_train2014.log 2>&1 &
wget http://images.cocodataset.org/zips/val2014.zip
# nohup wget http://images.cocodataset.org/zips/val2014.zip > wget_val2014.log 2>&1 &
wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip

#### 解压数据
unzip train2014.zip
unzip val2014.zip
unzip annotations_trainval2014.zip

#### 删除压缩包
rm train2014.zip
rm val2014.zip
rm annotations_trainval2014.zip
```

## Expected dataset structure for LVIS:
```
coco/
  {train,val}2017/
lvis/
  lvis_v0.5_{train,val}.json
  lvis_v0.5_train_{freq,common,rare}.json
```

在`lvis/`文件夹下，运行以下命令

```python
#### 下载LVIS v0.5的训练集标注和验证集标注（LVIS uses the COCO 2017 train, validation, and test image sets）
wget https://s3-us-west-2.amazonaws.com/dl.fbaipublicfiles.com/LVIS/lvis_v0.5_train.json.zip
wget https://s3-us-west-2.amazonaws.com/dl.fbaipublicfiles.com/LVIS/lvis_v0.5_val.json.zip

#### 解压压缩包
unzip lvis_v0.5_train.json.zip
unzip lvis_v0.5_val.json.zip


#### 删除压缩包
rm lvis_v0.5_train.json.zip 
rm lvis_v0.5_val.json.zip 
```

LVIS uses the same images and annotation format as COCO. You can use [split_lvis_annotation.py](split_lvis_annotation.py) to split `lvis_v0.5_train.json` into `lvis_v0.5_train_{freq,common,rare}.json`.

Install lvis-api by:
```
pip install git+https://github.com/lvis-dataset/lvis-api.git
```
或者
```
pip install lvis
```

# Few-shot datasets

对于每个dataset，我们通过随机采样额外构建了几组few-shot dataset，同时也使用FSRW提供的few-shot dataset。

For each dataset, we additionally create few-shot versions by sampling shots for each novel category. For better comparisons, we sample multiple groups of training shots in addition to the ones provided in previous works. We include the sampling scripts we used for better reproducibility and extensibility. 

可以这样下载数据集
```bash
wget -r -np -nH -R index.html http://dl.yf.io/fs-det/datasets/ # 速度较慢，可以选择后台执行
# wget -r -b -np -nH -R index.html http://dl.yf.io/fs-det/datasets/ # 后台执行
find ./fs-det/ -name '*.tmp' -delete # 删除index.html.tmp
mv ./fs-det/datasets/* ./datasets/ # 移动文件
rm -rf ./fs-det # 删除文件夹
```

The few-shot dataset files can be found [here](http://dl.yf.io/fs-det/datasets/). 


They should have the following directory structure:

## Pascal VOC:
```python
vocsplit/
  box_{1,2,3,5,10}shot_{category}_train.txt # FSRW的few-shot dataset
  seed{1-29}/ # 新生成的29组few-shot dataset
    shots
```

**每个文件包含某个类别的K-shot的图片。如果图片中包含多于K个instance，则随机采样K个instance**

Each file contains the images for _K_ shots for a specific category. There may be more instances in the images than _K_; in these cases, we randomly sample _K_ instances.


文件夹`vocsplit`中的shots就是FSRW中的shots，文件夹`seed{1-29}`中的shots是使用[prepare_voc_few_shot.py](prepare_voc_few_shot.py)采样得到的29组set。

The shots in the `vocsplit` directory are the same shots used by previous works. We additionally sample 29 more groups of shots for a total of 30 groups, which can be generated by using [prepare_voc_few_shot.py](prepare_voc_few_shot.py).

See [prepare_voc_few_shot.py](prepare_voc_few_shot.py) for generating the seeds yourself.

在config文件中，你需要在`DATASETS`处指定使用哪个训练集和测试集。下面列出数据集名称和它们对应的数据

In the config files, you have to specify the datasets to use. See our provided config files for more usage details. Below, we list out the names of the datasets and the data they correspond to:
```
voc_20{07,12}_trainval_{base,all}{1,2,3}        # Train/val datasets with base categories or all
                                                  categories for splits 1, 2, and 3.
voc_2007_trainval_all{1,2,3}_{1,2,3,5,10}shot   # Balanced subsets for splits 1, 2, and 3 containing
                                                  1, 2, 3, 5, or 10 shots for each category. You only
                                                  need to specify 2007, as it will load in both 2007
                                                  and 2012 automatically.
voc_2007_trainval_novel{1,2,3}_{1,2,3,5,10}shot # Same as previous datasets, but only contains data
                                                  of novel categories.
voc_2007_test_{base,novel,all}{1,2,3}           # Test datasets with base categories, novel categories,
                                                  or all categories for splits 1, 2, and 3.
```

## COCO:
```python
cocosplit/
  datasplit/
    trainvalno5k.json # 训练集
    5k.json # 测试集
  full_box_{1,2,3,5,10,30}shot_{category}_trainval.json # FSRW的few-shot dataset
  seed{1-9}/ # 新生成的9组few-shot dataset
    shots
```

train set和val set中，val set中5k张图片用作test set（`5k.json`），其余照片用作traing set（`trainvalno5k.json`）

All but 5k images from the train/val sets are used for training, while 5k images from the val set are used as the test set. `trainvalno5k.json` denotes the training set and `5k.json` is the test set.

**few-shot dataset的采样步骤和VOC数据集相同，但这里为每个class准确地采样k个instance，并且只采样10组（10=9+1）**。采样代码见[prepare_coco_few_shot.py](prepare_coco_few_shot.py)

The sampling procedure is the same as for Pascal VOC, except we sample exactly _K_ instances for each category. For COCO, we use 10 groups.

See [prepare_coco_few_shot.py](prepare_coco_few_shot.py) for generating the seeds yourself.

config文件中dataset的名称及说明如下所示

Dataset names for config files:
```
coco_trainval_{base,all}                        # Train/val datasets with base categories or all
                                                  categories.
coco_trainval_all_{1,2,3,5,10,30}shot           # Balanced subsets containing 1, 2, 3, 5, 10, or 30
                                                  shots for each category.
coco_trainval_novel_{1,2,3,5,10,30}shot         # Same as previous datasets, but only contains data
                                                  of novel categories.
coco_test_{base,novel,all}                      # Test datasets with base categories, novel categories,
                                                  or all categories.
```

## LVIS:
```
lvissplit/
  lvis_shots.json
```

我们将frequent classes和common classes作为base classes，将rare classes作为novel classes

We treat the frequent and common categories as the base categories and the rare categories as the novel categories.

为每个class采样10个instance，保存在单个COCO-style标注文件中

We sample up to 10 instances for each category to build a balanced subset for the few-shot fine-tuning stage. We include all shots in a single COCO-style annotation file.

See [prepare_lvis_few_shot.py](prepare_lvis_few_shot.py) for generating the seeds yourself.

config文件中dataset的名称及说明如下所示

Dataset names for config files:
```
lvis_v0.5_train_{freq,common}                   # Train datasets with freq categories or common
                                                  categories. These are used as the base datasets.
lvis_v0.5_train_rare_novel                      # Train datasets with rare categories.
lvis_v0.5_train_shots                           # Balanced subset containing up to 10 shots for
                                                  each category.
lvis_v0.5_val                                   # Validation set with all categories.
lvis_v0.5_val_novel                             # Validation set with only novel categories.
```
